---
title: "Empirical pipeline"
author: "Thomas Guillerme"
date: "`r Sys.Date()`"
output:
  html_document:
    fig_width: 12
    fig_height: 6
---

This script is the repeatable script for measuring changes in the different diversity metrics and how they are affected by the empirical data. 

## Requirements for the simulations

In order to run the simulations (on your machine, cluster, etc...) you'll need to load the following in your current environment:

```{r, eval = FALSE}
## Getting the non-CRAN (yet) libraries
library(devtools)
devtools::install_github("TGuillerme/treats")
install.packages(c("dispRity", "BAT", "FD", "ks", "TPD"))
```

```{r}
## Libraries
require(treats)
require(dispRity)
require(BAT)
require(FD)
require(ks)
require(TPD)
```

> Note that the libraries do not need to be loaded (i.e. no need for `library()`) but needs to exist.

You'll also need the following custom functions (located in [here on github](https://github.com/TGuillerme/eco_metrics_simulations/tree/master/Functions))

```{r}
## Loading the functions
source("../Functions/melodic.rao.R")
source("../Functions/make.simulation.pipeline.R")
source("../Functions/simulation.pipeline.R")
source("../Functions/analyse.replicates.R")
source("../Functions/dbFD.R")
```

## Setting up the empirical data

To run the simulations on an empirical data set you'll need to:

 1. load an empirical traitspace
 2. load a list of species to remove
 3. generate the pipeline as for the simulated data

Here's the pipeline applied to the Hawaiian birds dataset/

```{r}
## global trait space 
empirical_traitspace <- read.csv('../Data/Raw/trait-space-5d-prehistoric-community.csv', row.names = 1) 

## Species lists
historic_species <- rownames(read.csv('../Data/Raw/historic-species-list-minus-a-flammeus.csv', row.names = 1))
extant_species <- rownames(read.csv('../Data/Raw/present-species-list-minus-a-flammeus.csv', row.names = 1))

## Traitspace groups
extant_group <- rownames(empirical_traitspace) %in% extant_species ## 37 species present
historic_group <- rownames(empirical_traitspace) %in% historic_species ## 63 species present
groups <- list("extant" = extant_group, "historic" = historic_group)
```

You can then use the function `make.simulation.pipeline` to set up the pipeline by specifying the input data and stressor (the list of species to remove):

```{r}
## Creating the function for running the empirical pipeline
empirical.pipeline <- make.simulation.pipeline(sim.data = empirical_traitspace,
                                               remove = groups)
```

And then you can just run the pipeline by calling this pipeline function:

```{r, eval = FALSE}
## Running the empirical pipeline
empirical.pipeline()
```

## Replicating the empirical pipeline

The pipeline also automatically generates a null model for each level of data removal.
To get enough variance on the null model we will replicate the pipeline $n$ times until adding 5% more replicates does not increase the overall variance by more than 5% for any metric.
In other words, we replicated each simulation $n$ times where $n$ is estimated so that $var(n + 0.05 \times n) < 0.05 \times var(n)$.

For that we will use the custom `optim.replicate()` function which comes with one diagnosis function (checking if the variance for each metric is < 0.05) and one summarising (summarising the output of `empirical.pipeline()` for diagnosis) function

```{r}
## Loading the optimisation functions
source("../Functions/optim.replicate.R")
source("../Functions/optim.helpers.R")
source("../Functions/analyse.replicates.R")
```

You can then run this replicate function that will start by running 20 replicates (`mimimum`) and will increase the number of replicates by 5% until reaching 170 replicates (`maximum`) or until the addition 5% increase does not increase the variance for each metric with each different level of removal by less than 5% (120 parameters!).

There are options to 

```{r, eval = TRUE}
## Running the full optimisation
results <- optim.replicate(input.fun = empirical.pipeline,
                           diagnose = var,
                           summarise = optim.summarise,
                           minimum = 20, maximum = 170,
                           stop.variance = 0.01,
                           verbose = TRUE,
                           bkp.path = "../Data/Processed/",
                           bkp.name = "empirical_data.rda")
```

> Note that you can use the parallel version by adding the argument `parallel = TRUE` that is automatised using the package `future` and `future.apply` which makes the whole process run on all your available cores but is way less verbose. Without using the parallel version, it takes roughly 10 hours (overnight) to run the analyses on an old 2.2Ghz 8GB core.


## Empirical example for box 2

```{r}
library(dispRity)
## Plotting the trait space
data <- custom.subsets(empirical_traitspace, group = lapply(groups, which))
pdf(file = "../Manuscript/Figures/empirical_example.pdf", height = 4, width = 4)
plot(data, legend = FALSE, col = c("blue", "orange"))
legend("topright", pch = 19, col = c("blue", "orange"), legend = c("Current species", "Pre 1500 species"))
dev.off()

## Measuring disparity
library(xtable)
xtable(summary(dispRity(data, metric = convhull.volume)))
xtable(summary(dispRity(data, metric = displacements)))
```

## Empirical number of dimensions selection


```{r}
library(dispRity)
pca <- readRDS("../Data/Processed/pca-object-historic-community.RDS")
data <- custom.subsets(pca$x, group = list(extant = extant_species, pre_1500 = historic_species))
pdf(file = "../Manuscript/Figures/empirical_data_dimensions.pdf", height = 8, width = 4)
plot(select.axes(data))
dev.off()
```