---
title: "Results"
author: "Thomas Guillerme"
date: "`r Sys.Date()`"
output:
  html_document:
    fig_width: 12
    fig_height: 6
---

This script is the repeatable script for measuring changes in the different diversity metrics and how they are affected by the different stressors. 
In this section we are going to analyse the results from the `optim.replicates` chain

```{r, echo = FALSE}
library(knitr)
library(xtable)
## Loading the functions
source("../Functions/extract.table.R")
source("../Functions/plot.metric.results.R")
source("../Functions/paired.tests.R")
source("../Functions/split.metric.R")
source("../Functions/fit.model.rm.R")
source("../Functions/fancy.table.R")
source("../Functions/fancy.plot.R")
source("../Functions/fancy.names.R")
```

```{r, echo = FALSE}
## Loading all results per dimensions

## Simulated results:
read.results <- function(nd, stressors = c("equalizing", "facilitation", "filtering", "competition")) {
  list_load <- list()
  for(one_stressor in stressors) {
    load(paste0("../Data/Processed/sim_", one_stressor, "_", nd, ".rda"))
    list_load[[length(list_load)+1]] <- bkp
    names(list_load)[length(list_load)] <- one_stressor
  }
  return(list_load)
}

all_results_2d <- read.results("2d")
all_results_3d <- read.results("3d")
all_results_4d <- read.results("4d")
all_results_5d <- read.results("5d")
all_results_8d <- read.results("8d")

all_results_2d500 <- read.results("2d500")
all_results_4d500 <- read.results("4d500")
all_results_2d1000 <- read.results("2d1000")
all_results_4d1000 <- read.results("4d1000")



## Empirical
load("../Data/Processed/empirical_data.rda")
empirical_results <- list("empirical" = bkp)
#rm1 = "extant", rm2 = "historic", rm3 = "prehistoric"
extants <- grep("rm1", colnames(empirical_results$empirical$results_table))
historics <- grep("rm2", colnames(empirical_results$empirical$results_table))
# prehistorics <- grep("rm3", colnames(empirical_results$empirical$results_table))
## Reorder by percentage removed (historics > prehistorics > extants)
empirical_results$empirical$results_table <- empirical_results$empirical$results_table[, c(historics, extants)]
```

# Results per metrics

Here I'm going to display the results in box plot for each metric in each broad category.
> We can probably think of a better way to display the results in the future.

For each metric displayed here:
 
 * The different colours correspond to the different stressors (equalizing, facilitation, filtering and competition)
 * The different density of each colours correspond to the different levels of each stressor (removing 20, 40, 60 or 80% of the data)
 * All the metrics values are centred on the null (random) stressor for each individual simulation (i.e. 1 dataset is simulated, X% of the data is removed, one time randomly, one time biased - following the stressor; the metric is calculated on both the random and the biased removal and the biased removal is then centred on the random one (`biased metric score - random metric score`) for each simulation).
 * All the centred metric values are then scaled to the absolute maximum change (`centred scores/max(abs(centred scores))`).

```{r, echo = FALSE}
## Sort the results per name
sort.metrics <- function(one_results, order) {

    ## Get the results table
    all_results <- colnames(one_results$results_table)

    ## Extract the metric names
    metrics <- unique(gsub("stressor_", "", gsub("random_", "", gsub("_rm.*", "", all_results))))  

    ## Reorder these names
    metrics <- metrics[order]

    ## Get the removal levels
    levels <- unique(gsub(".*_rm", "", all_results))

    ## Sort the metrics_names
    sorted_metrics <- unlist(lapply(as.list(metrics), function(x, levels) paste(x, levels, sep = "_rm"), levels = levels))
    ## Adding the random/stressor bits
    sorted_metrics <- c(apply(cbind(paste0("random_", sorted_metrics), paste0("stressor_", sorted_metrics)), 1, c))

    ## Match the new column order
    one_results$results_table <- one_results$results_table[, match(sorted_metrics, all_results)]
    
    ## Return the updated results
    return(one_results)
}

## Re-ordering results for fancyness
new_order <- c(# Richness
               13, 10, 9, 1,
               # Divergence
               15, 11, 2, #8,
               #7,
               4, #5,
               # Regularity
               14, 12, 3, 6)

all_results_2d <- lapply(all_results_2d, sort.metrics, order = new_order)
all_results_3d <- lapply(all_results_3d, sort.metrics, order = new_order)
all_results_4d <- lapply(all_results_4d, sort.metrics, order = new_order)
all_results_5d <- lapply(all_results_5d, sort.metrics, order = new_order)
all_results_8d <- lapply(all_results_8d, sort.metrics, order = new_order)
empirical_results <- lapply(empirical_results, sort.metrics, order = new_order)

all_results_2d500 <- lapply(all_results_2d500, sort.metrics, order = new_order)
all_results_4d500 <- lapply(all_results_4d500, sort.metrics, order = new_order)
all_results_2d1000 <- lapply(all_results_2d1000, sort.metrics, order = new_order)
all_results_4d1000 <- lapply(all_results_4d1000, sort.metrics, order = new_order)


## The different removal level names
removals <- c("20%", "40%", "60%", "80%")
## The colours
cols <- c("blue", "orange", "red", "green")

## Fancier names
fancy_names <- rev(
               c(
                 "Functional richness\nprobability density\nTPD::REND",
                 "Functional richness\nhypervolume\nBAT::kernel.alpha",
                 "Functional richness\nconvex hull\nBAT::hull.alpha",
                 "Alpha diversity\ndendrogram\nBAT::alpha",

                 "Divergence\nprobability density\nTPD::REND",             
                 "Functional dispersion\nhypervolume\nBAT::kernel.dispersion",
                 "Functional dispersion\ndendrogram\nBAT::dispersion",
                 #"Melodic Mean Pairwise Distance\ndistances\nmelodic.rao",
                 #"Melodic Rao\ndistances\nmelodic.rao",
                 "Rao's quadratic entropy\ndistances\nFD::dbFD()$RaoQ",
                 #"dissimilarity[FD]\ndivergence",

                 "Functional evenness\nprobability density\nTPD::REND",
                 "Functional evenness\nhypervolume\nBAT::kernel.evenness",
                 "Functional evenness\ndendrogram\nBAT::evenness",
                 "Functional evenness\ndistances\nFD::dbFD()$FEve"
               ))
```

## Scaling and centring the results

We centre the metric based on the null results by substracting the score of the metric from the randomly reduced trait space to the stressed trait space (i.e. $score_{centred} = score_{stressed} - score_{random}$).
We then scale the centred metric by dividing it by it's maximum absolute centred value between all stressors (i.e. $score_{scaled} = score_{centred} / \text{max}(|scores_{centred}|))$).

```{r, echo = FALSE}
## Extracting all the scaled results
scaled_cent_results_2d <- extract.table(all_results_2d, scale.method = "between")
scaled_cent_results_3d <- extract.table(all_results_3d, scale.method = "between")
scaled_cent_results_4d <- extract.table(all_results_4d, scale.method = "between")
scaled_cent_results_5d <- extract.table(all_results_5d, scale.method = "between")
scaled_cent_results_8d <- extract.table(all_results_8d, scale.method = "between")
scaled_cent_results_emp<- extract.table(empirical_results, scale.method = "between")

scaled_cent_results_2d500 <- extract.table(all_results_2d500, scale.method = "between")
scaled_cent_results_4d500 <- extract.table(all_results_4d500, scale.method = "between")
scaled_cent_results_2d1000 <- extract.table(all_results_2d1000, scale.method = "between")
scaled_cent_results_4d1000 <- extract.table(all_results_4d1000, scale.method = "between")



## Extracting all the results but not centred (still scaled)
scaled_results_2d <- extract.table(all_results_2d, scale.method = "between", centre = FALSE)
scaled_results_3d <- extract.table(all_results_3d, scale.method = "between", centre = FALSE)
scaled_results_4d <- extract.table(all_results_4d, scale.method = "between", centre = FALSE)
scaled_results_5d <- extract.table(all_results_5d, scale.method = "between", centre = FALSE)
scaled_results_8d <- extract.table(all_results_8d, scale.method = "between", centre = FALSE)
scaled_results_emp<- extract.table(empirical_results, scale.method = "between", centre = FALSE)

scaled_results_2d500 <- extract.table(all_results_2d500, scale.method = "between", centre = FALSE)
scaled_results_4d500 <- extract.table(all_results_4d500, scale.method = "between", centre = FALSE)
scaled_results_2d1000 <- extract.table(all_results_2d1000, scale.method = "between", centre = FALSE)
scaled_results_4d1000 <- extract.table(all_results_4d1000, scale.method = "between", centre = FALSE)



## Extracting all the results not scaled
raw_results_2d <- extract.table(all_results_2d, scale = FALSE, centre = FALSE)
raw_results_3d <- extract.table(all_results_3d, scale = FALSE, centre = FALSE)
raw_results_4d <- extract.table(all_results_4d, scale = FALSE, centre = FALSE)
raw_results_5d <- extract.table(all_results_5d, scale = FALSE, centre = FALSE)
raw_results_8d <- extract.table(all_results_8d, scale = FALSE, centre = FALSE)
raw_results_emp<- extract.table(empirical_results, scale = FALSE, centre = FALSE)

raw_results_2d500 <- extract.table(all_results_2d500,scale = FALSE, centre = FALSE)
raw_results_4d500 <- extract.table(all_results_4d500, scale = FALSE, centre = FALSE)
raw_results_2d1000 <- extract.table(all_results_2d1000, scale = FALSE, centre = FALSE)
raw_results_4d1000 <- extract.table(all_results_4d1000, scale = FALSE, centre = FALSE)

```


## Measuring the statistics for each metric

To measure the differences between the random and stressed metric scores, we ran paired t-tests between each pairs of unscaled metric score for the random reduction of the trait space and the stressed reduction of the trait space (`t.test(random_scores, stressor_scores, paired = TRUE)`).

To check the trend in the different level of data removals (20, 40, 60 and 80%) using a linear model with the $scores_{scaled}$ as a response to the different removal levels (`lm(scaled_metric ~ removal_level`).

```{r, echo = FALSE}
## Slope and R2 for each model
model_fits_2d  <- lapply(scaled_cent_results_2d, fit.model.rm)
model_fits_3d  <- lapply(scaled_cent_results_3d, fit.model.rm)
model_fits_4d  <- lapply(scaled_cent_results_4d, fit.model.rm)
model_fits_5d  <- lapply(scaled_cent_results_5d, fit.model.rm)
model_fits_8d  <- lapply(scaled_cent_results_8d, fit.model.rm)
model_fits_emp <- lapply(scaled_cent_results_emp, fit.model.rm)

## Differences between stressor and random
null_differences_2d  <- lapply(all_results_2d, paired.tests)
null_differences_3d  <- lapply(all_results_3d, paired.tests)
null_differences_4d  <- lapply(all_results_4d, paired.tests)
null_differences_5d  <- lapply(all_results_5d, paired.tests)
null_differences_8d  <- lapply(all_results_8d, paired.tests)
null_differences_emp <- lapply(empirical_results, paired.tests)

## Making the fancy tables for the models
model_table_2d  <- fancy.table(model_fits_2d, columns = list(c(3,4), 5))
model_table_3d  <- fancy.table(model_fits_3d, columns = list(c(3,4), 5))
model_table_4d  <- fancy.table(model_fits_4d, columns = list(c(3,4), 5))
model_table_5d  <- fancy.table(model_fits_5d, columns = list(c(3,4), 5))
model_table_8d  <- fancy.table(model_fits_8d, columns = list(c(3,4), 5))
model_table_emp <- fancy.table(model_fits_emp, columns = list(c(3,4), 5))
## For the differences
columns_diff_ses <- list(c(1,3), 4)
columns_diff_ses <- c(columns_diff_ses,
                      lapply(columns_diff_ses, `+`, 4),
                      lapply(columns_diff_ses, `+`, 8),
                      lapply(columns_diff_ses, `+`, 12))
null_table_2d   <- fancy.table(null_differences_2d, columns = columns_diff_ses, digits = 2)
null_table_3d   <- fancy.table(null_differences_3d, columns = columns_diff_ses, digits = 2)
null_table_4d   <- fancy.table(null_differences_4d, columns = columns_diff_ses, digits = 2)
null_table_5d   <- fancy.table(null_differences_5d, columns = columns_diff_ses, digits = 2)
null_table_8d   <- fancy.table(null_differences_8d, columns = columns_diff_ses, digits = 2)
null_table_emp  <- fancy.table(null_differences_emp, columns = list(c(1,3), 4, c(1,3)+4, 4+4), digits = 2)


model_fits_2d500  <- lapply(scaled_cent_results_2d500, fit.model.rm)
null_differences_2d500  <- lapply(all_results_2d500, paired.tests)
model_table_2d500  <- fancy.table(model_fits_2d500, columns = list(c(3,4), 5))
null_table_2d500   <- fancy.table(null_differences_2d500, columns = columns_diff_ses, digits = 2)
model_fits_4d500  <- lapply(scaled_cent_results_4d500, fit.model.rm)
null_differences_4d500  <- lapply(all_results_4d500, paired.tests)
model_table_4d500  <- fancy.table(model_fits_4d500, columns = list(c(3,4), 5))
null_table_4d500   <- fancy.table(null_differences_4d500, columns = columns_diff_ses, digits = 2)

model_fits_2d1000  <- lapply(scaled_cent_results_2d1000, fit.model.rm)
null_differences_2d1000  <- lapply(all_results_2d1000, paired.tests)
model_table_2d1000  <- fancy.table(model_fits_2d1000, columns = list(c(3,4), 5))
null_table_2d1000   <- fancy.table(null_differences_2d1000, columns = columns_diff_ses, digits = 2)
model_fits_4d1000  <- lapply(scaled_cent_results_4d1000, fit.model.rm)
null_differences_4d1000  <- lapply(all_results_4d1000, paired.tests)
model_table_4d1000  <- fancy.table(model_fits_4d1000, columns = list(c(3,4), 5))
null_table_4d1000   <- fancy.table(null_differences_4d1000, columns = columns_diff_ses, digits = 2)

```

#### Printing the latex tables for the models

```{r, echo = FALSE, eval = FALSE}
# rownames(model_table_2d) <- gsub("\\]", "_", gsub("\\[", "_", gsub("\n", "", fancy_names)))
change.names <- function(table, fancy_names, output = "xtable", colnames = FALSE) {
  if(output == "xtable") {
    ## Format the row names for xtable
    ## split should be \\ and the third element should be \texttt{}
    row_names <- sapply(fancy_names, strsplit, split = "\\n")
    add.ttt <- function(x) {
      x[[3]] <- paste0("\\texttt{", x[[3]], "}")
      return(x)
    }
    row_names <- lapply(row_names, add.ttt)
    row_names <- lapply(row_names, function(x) paste(x, collapse = "\\\\"))
  }
  if(colnames) {
    colnames(table) <- gsub("equalizing", "EQ", colnames(table))
    colnames(table) <- gsub("facilitation", "FA", colnames(table))
    colnames(table) <- gsub("filtering", "FI", colnames(table))
    colnames(table) <- gsub("competition", "CO", colnames(table))
    colnames(table) <- gsub("rm", "", colnames(table))
  }
  rownames(table) <- row_names
  return(table)
}
# kable(model_table_2d, caption = "Results of the model scaled metric ~ removal level per stressor (2D)", align = "c")
print(xtable(change.names(model_table_2d, fancy_names), caption = "Results of the model scaled metric ~ removal level per stressor (2D)"), file = "../Manuscript/Tables/results_model2d.tex")

print(xtable(change.names(model_table_4d, fancy_names), caption = "Results of the model scaled metric ~ removal level per stressor (4D)"), file = "../Manuscript/Tables/results_model4d.tex")

print(xtable(change.names(model_table_8d, fancy_names), caption = "Results of the model scaled metric ~ removal level per stressor (8D)"), file = "../Manuscript/Tables/results_model8d.tex")

print(xtable(change.names(model_table_emp, fancy_names), caption = "Results of the model scaled metric ~ removal level per stressor (empirical data)"), file = "../Manuscript/Tables/results_empirical.tex")
```

#### Printing the latex tables for the differences

```{r, echo = FALSE, eval = FALSE}
print(xtable(change.names(null_table_2d[, 1:8], fancy_names, colnames = TRUE),
  caption = "Average difference between the null metric and the stressed metric (raw) for each level of removal and each stressor (2D). EQ = equalising; d = difference, s = standardised effect size; 1 to 4 correspond to the levels of data removal (20\\%, 40\\%, 60\\% and 80\\%). Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1."),
  file = "../Manuscript/Tables/results_differences2d_1.tex")

print(xtable(change.names(null_table_2d[, 9:16], fancy_names, colnames = TRUE),
  caption = "Average difference between the null metric and the stressed metric (raw) for each level of removal and each stressor (2D). FA = facilitation; d = difference, s = standardised effect size; 1 to 4 correspond to the levels of data removal (20\\%, 40\\%, 60\\% and 80\\%). Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1."),
  file = "../Manuscript/Tables/results_differences2d_2.tex")

print(xtable(change.names(null_table_2d[, 17:24], fancy_names, colnames = TRUE),
  caption = "Average difference between the null metric and the stressed metric (raw) for each level of removal and each stressor (2D). FI = filtering; d = difference, s = standardised effect size; 1 to 4 correspond to the levels of data removal (20\\%, 40\\%, 60\\% and 80\\%). Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1."),
  file = "../Manuscript/Tables/results_differences2d_3.tex")

print(xtable(change.names(null_table_2d[, 25:32], fancy_names, colnames = TRUE),
  caption = "Average difference between the null metric and the stressed metric (raw) for each level of removal and each stressor (2D).CO = competition; d = difference, s = standardised effect size; 1 to 4 correspond to the levels of data removal (20\\%, 40\\%, 60\\% and 80\\%). Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1."),
  file = "../Manuscript/Tables/results_differences2d_4.tex")



print(xtable(change.names(null_table_4d[, 1:8], fancy_names, colnames = TRUE),
  caption = "Average difference between the null metric and the stressed metric (raw) for each level of removal and each stressor (4D). EQ = equalising; d = difference, s = standardised effect size; 1 to 4 correspond to the levels of data removal (20\\%, 40\\%, 60\\% and 80\\%). Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1."),
  file = "../Manuscript/Tables/results_differences4d_1.tex")

print(xtable(change.names(null_table_4d[, 9:16], fancy_names, colnames = TRUE),
  caption = "Average difference between the null metric and the stressed metric (raw) for each level of removal and each stressor (4D). FA = facilitation; d = difference, s = standardised effect size; 1 to 4 correspond to the levels of data removal (20\\%, 40\\%, 60\\% and 80\\%). Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1."),
  file = "../Manuscript/Tables/results_differences4d_2.tex")

print(xtable(change.names(null_table_4d[, 17:24], fancy_names, colnames = TRUE),
  caption = "Average difference between the null metric and the stressed metric (raw) for each level of removal and each stressor (4D). FI = filtering; d = difference, s = standardised effect size; 1 to 4 correspond to the levels of data removal (20\\%, 40\\%, 60\\% and 80\\%). Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1."),
  file = "../Manuscript/Tables/results_differences4d_3.tex")

print(xtable(change.names(null_table_4d[, 25:32], fancy_names, colnames = TRUE),
  caption = "Average difference between the null metric and the stressed metric (raw) for each level of removal and each stressor (4D).CO = competition; d = difference, s = standardised effect size; 1 to 4 correspond to the levels of data removal (20\\%, 40\\%, 60\\% and 80\\%). Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1."),
  file = "../Manuscript/Tables/results_differences4d_4.tex")




print(xtable(change.names(null_table_8d[, 1:8], fancy_names, colnames = TRUE),
  caption = "Average difference between the null metric and the stressed metric (raw) for each level of removal and each stressor (8D). EQ = equalising; d = difference, s = standardised effect size; 1 to 4 correspond to the levels of data removal (20\\%, 40\\%, 60\\% and 80\\%). Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1."),
  file = "../Manuscript/Tables/results_differences8d_1.tex")

print(xtable(change.names(null_table_8d[, 9:16], fancy_names, colnames = TRUE),
  caption = "Average difference between the null metric and the stressed metric (raw) for each level of removal and each stressor (8D). FA = facilitation; d = difference, s = standardised effect size; 1 to 4 correspond to the levels of data removal (20\\%, 40\\%, 60\\% and 80\\%). Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1."),
  file = "../Manuscript/Tables/results_differences8d_2.tex")

print(xtable(change.names(null_table_8d[, 17:24], fancy_names, colnames = TRUE),
  caption = "Average difference between the null metric and the stressed metric (raw) for each level of removal and each stressor (8D). FI = filtering; d = difference, s = standardised effect size; 1 to 4 correspond to the levels of data removal (20\\%, 40\\%, 60\\% and 80\\%). Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1."),
  file = "../Manuscript/Tables/results_differences8d_3.tex")

print(xtable(change.names(null_table_8d[, 25:32], fancy_names, colnames = TRUE),
  caption = "Average difference between the null metric and the stressed metric (raw) for each level of removal and each stressor (8D).CO = competition; d = difference, s = standardised effect size; 1 to 4 correspond to the levels of data removal (20\\%, 40\\%, 60\\% and 80\\%). Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1."),
  file = "../Manuscript/Tables/results_differences8d_4.tex")



print(xtable(change.names(null_table_emp, fancy_names, colnames = TRUE),
  caption = "Average difference between the null metric and the stressed metric (raw) for each level of removal and each
stressor (empirical); d = difference, s = standardised effect size. Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1."),
  file = "../Manuscript/Tables/results_differencesempirical.tex")
```


<!-- Table cleaning (in shell)

## Cleaning (in shell)
## search replace
## $\backslash$ by \
## \{ by {
## \} by }
## \centering by \scriptsize\n\centering

 -->

# Plots per stressor

```{r, fig.width = 8, fig.height = 10, echo = FALSE}
col_vector <- c(rep("darkgreen", 4), # The regularity ones
                rep("orange", 4), # The divergence ones
                rep("blue", 4)) # The richness ones
## The plot
fancy.plot(scaled_cent_results_2d, col = col_vector, lm = model_fits_2d, null = null_differences_2d, metric.names = fancy_names, pch = rep(19,4), xlab = "scaled metric change", xlim = c(-1, 1))

## Pdf version
pdf(file = "../Manuscript/Figures/results_per_metric_per_stressor_2d.pdf", height = 9, width = 9)
fancy.plot(scaled_cent_results_2d, col = col_vector, lm = model_fits_2d, null = null_differences_2d, metric.names = fancy_names, pch = rep(19,4), xlim = c(-1, 1))
dev.off()
```

Figure 1: Simulation results: the y axes represent the different metrics tested (sorted by categories). The different columns represent the different stressors. The x-axes represent the metric values centred on the random changes and scaled by the maximum value for each metric between the four stressors. Negative and positive values signify a decrease/increase in the metric score. The dots represent the median metric value, the full line their 50% confidence interval (CI) and the dashed line their 95% CI. The colours are just here to visually separate the metrics rows but the colour gradient within each row corresponds to a removal of respectively 80%, 60%, 40% and 20% of the data (from top to bottom). Grey lines in the background are a fitted linear model on the scaled metric score function of removal amount and the value displayed is the adjusted R^2 from each of these models. Dashed grey lines represent non-significant models (slope or/and intercept). The grey line plots represent distribution of metrics scores not clearly different from the random metric scores (paired t-test p value > 0.05).


```{r}
## The plot
fancy.plot(scaled_cent_results_3d, col = col_vector, lm = model_fits_3d, null = null_differences_3d, metric.names = fancy_names, pch = rep(19,4), xlim = c(-1, 1))

## Pdf version
pdf(file = "../Manuscript/Figures/results_per_metric_per_stressor_3d.pdf", height = 9, width = 9)
fancy.plot(scaled_cent_results_3d, col = col_vector, lm = model_fits_3d, null = null_differences_3d, metric.names = fancy_names, pch = rep(19,4), xlim = c(-1, 1))
dev.off()
```


```{r}
## The plot
fancy.plot(scaled_cent_results_4d, col = col_vector, lm = model_fits_4d, null = null_differences_4d, metric.names = fancy_names, pch = rep(19,4), xlim = c(-1, 1))

## Pdf version
pdf(file = "../Manuscript/Figures/results_per_metric_per_stressor_4d.pdf", height = 9, width = 9)
fancy.plot(scaled_cent_results_4d, col = col_vector, lm = model_fits_4d, null = null_differences_4d, metric.names = fancy_names, pch = rep(19,4), xlim = c(-1, 1))
dev.off()
```


```{r}
## The plot
fancy.plot(scaled_cent_results_5d, col = col_vector, lm = model_fits_5d, null = null_differences_5d, metric.names = fancy_names, pch = rep(19,4), xlim = c(-1, 1))

## Pdf version
pdf(file = "../Manuscript/Figures/results_per_metric_per_stressor_5d.pdf", height = 9, width = 9)
fancy.plot(scaled_cent_results_5d, col = col_vector, lm = model_fits_5d, null = null_differences_5d, metric.names = fancy_names, pch = rep(19,4), xlim = c(-1, 1))
dev.off()
```


```{r}
## The plot
fancy.plot(scaled_cent_results_8d, col = col_vector, lm = model_fits_8d, null = null_differences_8d, metric.names = fancy_names, pch = rep(19,4), xlim = c(-1, 1))

## Pdf version
pdf(file = "../Manuscript/Figures/results_per_metric_per_stressor_8d.pdf", height = 9, width = 9)
fancy.plot(scaled_cent_results_8d, col = col_vector, lm = model_fits_8d, null = null_differences_8d, metric.names = fancy_names, pch = rep(19,4), xlim = c(-1, 1))
dev.off()
```



```{r}
## The plot
fancy.plot(scaled_cent_results_emp, col = col_vector, lm = NULL, null = null_differences_emp, metric.names = fancy_names, pch = c(19,15,17), xlim = c(-1, 1))

## Pdf version
pdf(file = "../Manuscript/Figures/results_per_metric_per_stressor_emp.pdf", height = 11, width = 3.5)
fancy.plot(scaled_cent_results_emp, col = col_vector, lm = NULL, null = null_differences_emp, metric.names = fancy_names, pch = c(19,15,17), xlim = c(-1, 1))
dev.off()
```

Figure 3: Empirical data. Plain circles represents the metric for historic data (53 % - 63/118 species), lightly fainted squares for prehistoric data (46% - 55/118 species), and fainted triangles for extant data (31% - 37/118 species).


```{r}
## Pdf version
pdf(file = "../Manuscript/Figures/results_per_metric_per_stressor_2d500.pdf", height = 9, width = 9)
fancy.plot(scaled_cent_results_2d500, col = col_vector, lm = model_fits_2d500, null = null_differences_2d500, metric.names = fancy_names, pch = rep(19,4), xlim = c(-1, 1))
dev.off()

pdf(file = "../Manuscript/Figures/results_per_metric_per_stressor_4d500.pdf", height = 9, width = 9)
fancy.plot(scaled_cent_results_4d500, col = col_vector, lm = model_fits_4d500, null = null_differences_4d500, metric.names = fancy_names, pch = rep(19,4), xlim = c(-1, 1))
dev.off()

## Pdf version
pdf(file = "../Manuscript/Figures/results_per_metric_per_stressor_2d1000.pdf", height = 9, width = 9)
fancy.plot(scaled_cent_results_2d1000, col = col_vector, lm = model_fits_2d1000, null = null_differences_2d1000, metric.names = fancy_names, pch = rep(19,4), xlim = c(-1, 1))
dev.off()

pdf(file = "../Manuscript/Figures/results_per_metric_per_stressor_4d1000.pdf", height = 9, width = 9)
fancy.plot(scaled_cent_results_4d1000, col = col_vector, lm = model_fits_4d1000, null = null_differences_4d1000, metric.names = fancy_names, pch = rep(19,4), xlim = c(-1, 1))
dev.off()
```





## Raw results per metric

```{r}

pdf(file = "../Manuscript/Figures/scaled_results_per_metric_per_stressor_2d.pdf", height = 11, width = 8.5)
fancy.plot(scaled_results_2d, col = col_vector, lm = NULL, null = NULL, metric.names = fancy_names, pch = rep(19,5), xlab = "scaled metric", xlim = c(0,1))
dev.off()

pdf(file = "../Manuscript/Figures/scaled_results_per_metric_per_stressor_4d.pdf", height = 11, width = 8.5)
fancy.plot(scaled_results_4d, col = col_vector, lm = NULL, null = NULL, metric.names = fancy_names, pch = rep(19,5), xlab = "scaled metric", xlim = c(0,1))
dev.off()

pdf(file = "../Manuscript/Figures/scaled_results_per_metric_per_stressor_8d.pdf", height = 11, width = 8.5)
fancy.plot(scaled_results_8d, col = col_vector, lm = NULL, null = NULL, metric.names = fancy_names, pch = rep(19,5), xlab = "scaled metric", xlim = c(0,1))
dev.off()

pdf(file = "../Manuscript/Figures/scaled_results_per_metric_per_stressor_emp.pdf", height = 11, width = 5.5)
fancy.plot(scaled_results_emp, col = col_vector, lm = NULL, null = NULL, metric.names = fancy_names, pch = c(19,15,17), xlab = "scaled metric", xlim = c(0,1))
dev.off()
```



## Raw results per metric

```{r}
# pdf(file = "../Manuscript/Figures/raw_results_per_metric_per_stressor_2d.pdf", height = 11, width = 8.5)



# layout(matrix(1:(12*5), 12, 5))
# for(stressor in 1:5) {
#     ## For each stressor
#     plotting_data <- raw_results_2d[[stressor]]
#     ## Plot the metric
#     for(one_metric in 1:(ncol(plotting_data)/4)) {
#         ## Get the metric name
#         metric_name <- strsplit(colnames(selected_data), split = "_rm")[[1]][1]
#         ## Get the data
#         selected_data <- plotting_data[, 1:4]

#         ## Get the color TODO + add transparent
#         col <- rep("orange", 4)

#         ## Empty plot
#         plot(NULL, ylim = c(0, 5), xlim = quantile(c(selected_data), prob =  c(0.025, 0.975)), yaxt = "n", ylab = "", xlab = metric_name)

#         ## Add the lines
#         for(one_line in 1:4) {
#             ## Get the CIs and median
#             CIs <- quantile(selected_data[, one_line], prob = c(0.025, 0.25, 0.75, 0.975))
#             med <- median(selected_data[, one_line])
#             ## Plot the CIs
#             lines(y = rep(5-one_line, 2), x = CIs[c(1, 4)], lty = 3, col = col)
#             lines(y = rep(5-one_line, 2), x = CIs[c(2, 3)], lty = 1, col = col)
#             ## Plot the median
#             points(y =5-one_line, x = med, pch = 19, col = col)
#         }
#     }
# }


# fancy.plot(raw_results_2d, col = col_vector, lm = NULL, null = NULL, metric.names = fancy_names, pch = rep(19,5), xlab = "raw metric")
# dev.off()

# pdf(file = "../Manuscript/Figures/raw_results_per_metric_per_stressor_4d.pdf", height = 11, width = 8.5)
# fancy.plot(raw_results_4d, col = col_vector, lm = NULL, null = NULL, metric.names = fancy_names, pch = rep(19,5), xlab = "raw metric")
# dev.off()

# pdf(file = "../Manuscript/Figures/raw_results_per_metric_per_stressor_8d.pdf", height = 11, width = 8.5)
# fancy.plot(raw_results_8d, col = col_vector, lm = NULL, null = NULL, metric.names = fancy_names, pch = rep(19,5), xlab = "raw metric")
# dev.off()

# pdf(file = "../Manuscript/Figures/raw_results_per_metric_per_stressor_emp.pdf", height = 11, width = 5.5)
# fancy.plot(raw_results_emp, col = col_vector, lm = NULL, null = NULL, metric.names = fancy_names, pch = c(19,15,17), xlab = "raw metric")
# dev.off()
```




## Get the computation time per metric type

```{r}
#@ combine logical, whether to combine the results per stressor (TRUE) or not (FALSE)
get.time.per.type <- function(all_results, combine = TRUE) {
  ## Get the timers per stressor
  get.time.per.stressors <- function(one_stressor_results) {
    return(do.call(rbind, lapply(one_stressor_results$output_save, function(x) return(log(as.numeric(as.difftime(x$timer, units = "secs")))))))
  }

  ## Get all the timers
  metrics_times <- lapply(all_results, get.time.per.stressors)

  ## Combine it
  if(combine) {
    metric_times <- do.call(rbind, metrics_times)
  }
}

## times per dimensions
times_2d <- apply(get.time.per.type(all_results_2d), 2, quantile, probs = c(0.025, 0.5, 0.975))
times_3d <- apply(get.time.per.type(all_results_3d), 2, quantile, probs = c(0.025, 0.5, 0.975))
times_4d <- apply(get.time.per.type(all_results_4d), 2, quantile, probs = c(0.025, 0.5, 0.975))
times_5d <- apply(get.time.per.type(all_results_5d), 2, quantile, probs = c(0.025, 0.5, 0.975))
times_8d <- apply(get.time.per.type(all_results_8d), 2, quantile, probs = c(0.025, 0.5, 0.975))

times_tree <- cbind(times_2d[,2], times_3d[,2], times_4d[,2], times_5d[,2], times_8d[,2])
times_dissimilarity <- cbind(times_2d[,3], times_3d[,3], times_4d[,3], times_5d[,3], times_8d[,3])
times_hull <- cbind(times_2d[,4], times_3d[,4], times_4d[,4], times_5d[,4], times_8d[,4])
times_hypervolume <- cbind(times_2d[,5], times_3d[,5], times_4d[,5], times_5d[,5], times_8d[,5])
times_probabilities <-  cbind(times_2d[,6], times_3d[,6], times_4d[,6], times_5d[,6], times_8d[,6])

## Plot times per dimensions
ylim <- range(c(times_tree, times_dissimilarity, times_hull, times_hypervolume, times_probabilities))
## Plot colours
metric_cols <- c("#d55e00", "#cc79a7", "#0072b2", "#f0e442", "#009e73")

pdf(file = "../Manuscript/Figures/time_per_metric.pdf", height = 6, width = 7)
par(mar =c(5, 4, 4, 4) + 0.1)
## Empty plot
plot(NULL, ylim = range(pretty(ylim)), xlim = c(2, 8), ylab = "Time (log(s))", xlab = "dimensions")
abline(h = c(1, 4.1, 7, 8.189), col = "grey")

## Medians
points(x = c(2,3,4,5,8)+0.00, c(times_tree[2,]), pch = 19, col = metric_cols[1])
points(x = c(2,3,4,5,8)+0.04, c(times_dissimilarity[2,]), pch = 19, col = metric_cols[2])
points(x = c(2,3,4,5,8)+0.08, c(times_hull[2,]), pch = 19, col = metric_cols[3])
points(x = c(2,3,4,5,8)+0.12, c(times_hypervolume[2,]), pch = 19, col = metric_cols[4])
points(x = c(2,3,4)+0.16, c(times_probabilities[2,c(1:3)]), pch = 19, col = metric_cols[5])
## Linkings
lines(x = c(2,3,4,5,8)+0.00, c(times_tree[2,]), pch = 19, col = metric_cols[1])
lines(x = c(2,3,4,5,8)+0.04, c(times_dissimilarity[2,]), pch = 19, col = metric_cols[2])
lines(x = c(2,3,4,5,8)+0.08, c(times_hull[2,]), pch = 19, col = metric_cols[3])
lines(x = c(2,3,4,5,8)+0.12, c(times_hypervolume[2,]), pch = 19, col = metric_cols[4])
lines(x = c(2,3,4)+0.16, c(times_probabilities[2,c(1:3)]), pch = 19, col = metric_cols[5])
## 95% CI
dimensions <- c(2,3,4,5,8)
for(one_ci in 1:5) {
  lines(y = c(times_tree[c(1,3), one_ci]), x = rep(dimensions[one_ci], 2)+0.00, col = metric_cols[1])
}
for(one_ci in 1:5) {
  lines(y = c(times_dissimilarity[c(1,3), one_ci]), x = rep(dimensions[one_ci], 2)+0.04, col = metric_cols[2])
}
for(one_ci in 1:5) {
  lines(y = c(times_hull[c(1,3), one_ci]), x = rep(dimensions[one_ci], 2)+0.08, col = metric_cols[3])
}
for(one_ci in 1:5) {
  lines(y = c(times_hypervolume[c(1,3), one_ci]), x = rep(dimensions[one_ci], 2)+0.12, col = metric_cols[4])
}
for(one_ci in 1:3) {
  lines(y = c(times_probabilities[c(1,3), one_ci]), x = rep(dimensions[one_ci], 2)+0.16, col = metric_cols[5])
}
## legend
legend("topleft", col = metric_cols, pch = 19, legend = c("dendrogram", "dissimilarity", "convex hull", "hypervolume", "probability density"))

## Time
axis(4, at = c(1, 4.1, 7, 8.189), labels = c("1 sec", "1 min", "30 min", "1 hour"), las = 2)
dev.off()

```

